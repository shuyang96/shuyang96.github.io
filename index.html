<head>
  <title>Yang Shu's home page</title>
  <meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
</head>
  <table width="900" border="0" align="center" cellspacing="0" cellpadding="20">
    <tbody><tr>
    <td>
      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="0">
      <tbody><tr>
        <td width="70%" valign="middle">
        <h1><strong>Yang Shu</strong></h1>
        <p><b>Lecturer<br>
           <a target='_blank' href='http://dase.ecnu.edu.cn/'> School of Data Science and Engineering</a>, <a target='_blank' href='https://english.ecnu.edu.cn/'> East China Normal University</a><br>
	  </b>
        </p>
	<p>
	Email: yshu@dase.ecnu.edu.cn<br>
	Mail: Room 109, Geography Building, 3663 North Zhongshan Road, Shanghai, China<br>
	<a target='_blank' href='https://scholar.google.com/citations?user=VdyHmIwAAAAJ'>Google Scholar</a>
        </p>
        </td>
        <td width="5%">
        </td>
        <td width="25%">
        <img src="shuyang.jpg" width = '180' height = '240'>
        </td>
      </tr>
  </tbody></table>


<br>
<table width="100%" align="center" border="0" cellspacing="0" cellpadding="0">
<tbody><tr><td>
      Our group's research lies in the intersection of machine learning and computer vision, especially in the areas of vision-based intuitive physics.
	We want to understand how the real world works through machine learning approaches 
		(e.g., predictive learning, inverse graphics, and model-based reinforcement learning).

    My research aims at creating strong learning machines that adapt to complex real world. I am working on transfer learning, out-of-distribution (OOD) generalization, domain adaptation and few-shot learning. I am also interested in some related topics in machine learning and deep learning, such as foundation models, multi-modal learning and spatiotemporal learning.


    <br><br>
      I received my Ph.D. degree from School of Software, Tsinghua University, advised by <a target='_blank' href="http://ise.thss.tsinghua.edu.cn/~mlong/">Mingsheng Long</a>. I received my B.S. degree from Department of Automation, Tsinghua University.
    <br>

 <h2>Preprints</h2>
 <ol>
    <li><strong>Transferability in Deep Learning: A Survey</strong><br>
	Junguang Jiang*, <strong>Yang Shu*</strong>, Jianmin Wang, Mingsheng Long<span style="font-family:Wingdings">*</span><br>
	[<a target='_blank' href="https://arxiv.org/abs/2201.05867">Paper</a>]
	 </li><br>
     <li><strong>Omni-Training: Bridging Pre-Training and Meta-Training for Few-Shot Learning</strong><br>
    <strong>Yang Shu</strong>, Zhangjie Cao, Jinghan Gao, Jianmin Wang, Philip S. Yu, Mingsheng Long<span style="font-family:Wingdings">*</span><br>
    [<a target='_blank' href="https://arxiv.org/abs/2110.07510">Paper</a>]
     </li><br>
 </ol>
	
 <h2>Publications</h2>
  <ol>
    <li><strong>CLIPood: Generalizing CLIP to Out-of-Distributions</strong><br>
	<strong>Yang Shu*</strong>, Xingzhuo Guo*, Ximei Wang, Jianmin Wang, Mingsheng Long<span style="font-family:Wingdings">*</span><br>
	<span><b><font color='#BB2222'>International Conference on Machine Learning (ICML), 2023</font></b></span>
	    [<a target='_blank' href="https://arxiv.org/abs/2302.00864">Paper</a>]
	[<a target='_blank' href="https://github.com/thuml/CLIPood">PyTorch Code</a>]
    </li><br>

    <li><strong>Hub-Pathway: Transfer Learning from A Hub of Pre-trained Models</strong><br>
	Yang Shu, Zhangjie Cao, Ziyang Zhang, Jianmin Wang, Mingsheng Long<span style="font-family:Wingdings">*</span><br>
	    <span><b><font color='#BB2222'>Neural Information Processing Systems (NeurIPS), 2022</font></b></span>
	[<a target='_blank' href="https://proceedings.neurips.cc/paper_files/paper/2022/hash/d470d6e007a19ff1666386562c77517c-Abstract-Conference.html">Paper</a>]
    </li><br>
	  
    <li><strong>Zoo-Tuning: Adaptive Transfer from A Zoo of Models</strong><br>
    <strong>Yang Shu*</strong>, Zhi Kou*, Zhangjie Cao, Jianmin Wang, Mingsheng Long<span style="font-family:Wingdings">*</span><br>
    <span><b><font color='#BB2222'>International Conference on Machine Learning (ICML), 2022</font></b></span>
        [<a target='_blank' href="https://arxiv.org/abs/2106.15434">Paper</a>]
    [<a target='_blank' href="https://github.com/thuml/Zoo-Tuning">PyTorch Code</a>]
    </li><br>

    <li><strong>Open Domain Generalization with Domain-Augmented Meta-Learning</strong><br>
    <strong>Yang Shu*</strong>, Zhangjie Cao*, Chenyu Wang, Jianmin Wang, Mingsheng Long<span style="font-family:Wingdings">*</span><br>
    <span><b><font color='#BB2222'>IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2021</font></b></span>
        [<a target='_blank' href="https://openaccess.thecvf.com/content/CVPR2021/html/Shu_Open_Domain_Generalization_with_Domain-Augmented_Meta-Learning_CVPR_2021_paper.html">Paper</a>]
    [<a target='_blank' href="https://github.com/thuml/OpenDG-DAML">PyTorch Code</a>]
    </li><br>

    <li><strong>Transferable Curriculum for Weakly-Supervised Domain Adaptation</strong><br>
    <strong>Yang Shu*</strong>, Zhangjie Cao, Mingsheng Long<span style="font-family:Wingdings">*</span>, Jianmin Wang<br>
    <span><b><font color='#BB2222'>AAAI Conference on Artificial Intelligence (AAAI), 2019</font></b></span>
        [<a target='_blank' href="https://ojs.aaai.org/index.php/AAAI/article/view/4425">Paper</a>]
    [<a target='_blank' href="https://github.com/thuml/TCL">PyTorch Code</a>]
    </li><br>

  </ol>


</td></tr>
